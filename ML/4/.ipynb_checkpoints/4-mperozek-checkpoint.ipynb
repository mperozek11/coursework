{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ed0f723-1a51-49d4-999b-0544ebe4936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab077dce-ab0d-452f-8205-e9d541553ca8",
   "metadata": {},
   "source": [
    "### 1\n",
    "Preprocess and normalize (or standardize) the dataset. Split it into training and testing subsets with 80% of the data in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9105387a-e6a2-4b8b-948a-201c72d59b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\n",
      "   This breast cancer databases was obtained from the University of Wisconsin\n",
      "   Hospitals, Madison from Dr. William H. Wolberg.  If you publish results\n",
      "   when using this database, then please include this information in your\n",
      "   acknowledgements.  Also, please cite one or more of:\n",
      "\n",
      "   1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear \n",
      "      programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n",
      "\n",
      "   2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology\", \n",
      "      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, \n",
      "      December 1990, pp 9193-9196.\n",
      "\n",
      "   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition \n",
      "      via linear programming: Theory and application to medical diagnosis\", \n",
      "      in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying\n",
      "      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\n",
      "\n",
      "   4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming \n",
      "      discrimination of two linearly inseparable sets\", Optimization Methods\n",
      "      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).\n",
      "\n",
      "1. Title: Wisconsin Breast Cancer Database (January 8, 1991)\n",
      "\n",
      "2. Sources:\n",
      "   -- Dr. WIlliam H. Wolberg (physician)\n",
      "      University of Wisconsin Hospitals\n",
      "      Madison, Wisconsin\n",
      "      USA\n",
      "   -- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
      "      Received by David W. Aha (aha@cs.jhu.edu)\n",
      "   -- Date: 15 July 1992\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   Attributes 2 through 10 have been used to represent instances.\n",
      "   Each instance has one of 2 possible classes: benign or malignant.\n",
      "\n",
      "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology. In\n",
      "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
      "      9193--9196.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Collected classification results: 1 trial only\n",
      "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
      "         50% of the data\n",
      "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
      "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
      "         67% of data\n",
      "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
      "\n",
      "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
      "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
      "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
      "      Kaufmann.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Applied 4 instance-based learning algorithms \n",
      "      -- Collected classification results averaged over 10 trials\n",
      "      -- Best accuracy result: \n",
      "         -- 1-nearest neighbor: 93.7%\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "      -- Also of interest:\n",
      "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
      "   The database therefore reflects this chronological grouping of the data.\n",
      "   This grouping information appears immediately below, having been removed\n",
      "   from the data itself:\n",
      "\n",
      "     Group 1: 367 instances (January 1989)\n",
      "     Group 2:  70 instances (October 1989)\n",
      "     Group 3:  31 instances (February 1990)\n",
      "     Group 4:  17 instances (April 1990)\n",
      "     Group 5:  48 instances (August 1990)\n",
      "     Group 6:  49 instances (Updated January 1991)\n",
      "     Group 7:  31 instances (June 1991)\n",
      "     Group 8:  86 instances (November 1991)\n",
      "     -----------------------------------------\n",
      "     Total:   699 points (as of the donated datbase on 15 July 1992)\n",
      "\n",
      "   Note that the results summarized above in Past Usage refer to a dataset\n",
      "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
      "   originally contained 369 instances; 2 were removed.  The following\n",
      "   statements summarizes changes to the original Group 1's set of data:\n",
      "\n",
      "   #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
      "   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
      "   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
      "   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
      "   #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
      "   #####                  : Changed 0 to 1 in field 8 of following sample:\n",
      "   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
      "\n",
      "5. Number of Instances: 699 (as of 15 July 1992)\n",
      "\n",
      "6. Number of Attributes: 10 plus the class attribute\n",
      "\n",
      "7. Attribute Information: (class attribute has been moved to last column)\n",
      "\n",
      "   #  Attribute                     Domain\n",
      "   -- -----------------------------------------\n",
      "   1. Sample code number            id number\n",
      "   2. Clump Thickness               1 - 10\n",
      "   3. Uniformity of Cell Size       1 - 10\n",
      "   4. Uniformity of Cell Shape      1 - 10\n",
      "   5. Marginal Adhesion             1 - 10\n",
      "   6. Single Epithelial Cell Size   1 - 10\n",
      "   7. Bare Nuclei                   1 - 10\n",
      "   8. Bland Chromatin               1 - 10\n",
      "   9. Normal Nucleoli               1 - 10\n",
      "  10. Mitoses                       1 - 10\n",
      "  11. Class:                        (2 for benign, 4 for malignant)\n",
      "\n",
      "8. Missing attribute values: 16\n",
      "\n",
      "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
      "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
      "\n",
      "9. Class distribution:\n",
      " \n",
      "   Benign: 458 (65.5%)\n",
      "   Malignant: 241 (34.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset info:\n",
    "\n",
    "data_info_path = '/Users/maxperozek/ML-CP341/4/breast-cancer-wisconsin.names'\n",
    "\n",
    "with open(data_info_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ce65108-8e57-4157-8951-8a0b4d7a817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/maxperozek/ML-CP341/4/breast-cancer-wisconsin.data'\n",
    "\n",
    "data = np.genfromtxt(data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2909609-b2a6-441f-ba91-17f17a84a172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7516ec0d-7633-4d1f-b753-46357c703c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_mean(X):\n",
    "    feat_means = np.nanmean(X, axis=0)\n",
    "    nan_idx = np.argwhere(np.isnan(X))\n",
    "    \n",
    "    for i in range(nan_idx.shape[0]):\n",
    "        X[nan_idx[i,:]] = feat_means[nan_idx[i,1]]\n",
    "        \n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e72b7d9-3a5f-4566-a677-04900b626315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(X):\n",
    "    normalized_array = normalize(X, norm=\"l2\")\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1733ad37-0361-46f7-b456-a58624f2eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data[:,1:10]\n",
    "data_y = data[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b67386d-565b-4187-b36a-574983e1cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = fill_empty_mean(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f3e7914-e7e7-4208-81e4-030e5af4f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 9)\n",
      "(699,)\n"
     ]
    }
   ],
   "source": [
    "print(data_X.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9f69cca-ce0f-4451-a1a1-99a527186ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = normalize_dataset(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1733bd47-1ce7-43b5-8f7d-dab94efaf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y[np.where(data_y == 2.0)] = 0\n",
    "data_y[np.where(data_y == 4.0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25c2af66-ba9e-4dd6-a547-3f309dafe495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91353d69-f874-4a3d-b3bb-de5c970827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_train = 0.8\n",
    "\n",
    "train_idx = np.random.choice(np.arange(data_X.shape[0]), int(data_X.shape[0] * pct_train),  replace=False)\n",
    "test_idx = np.array([i for i in range(data_X.shape[0]) if i not in list(train_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8260cba1-9a1b-4ab7-917b-a3576d0cd84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx.shape[0] + train_idx.shape[0] == data_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9fdacfa9-71f9-459c-b99b-2ebba41710e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data_X[train_idx, :]\n",
    "train_y = data_y[train_idx]\n",
    "\n",
    "test_X = data_X[test_idx, :]\n",
    "test_y = data_y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68da847b-f548-4c60-8b0b-721fa35775cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 9)\n",
      "(559,)\n",
      "(140, 9)\n",
      "(140,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da309ed-ec6c-4439-a382-a9cb2f7e7864",
   "metadata": {},
   "source": [
    "### 2 \n",
    "Create your ANN model using Keras. You can choose the various parameters of the network, such as number of layers, number of hidden nodes per layer, activation functions, etc. Be prepared to adjust your parameters if you encounter issues when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ddf2e4c-f833-4bcd-ae30-964be5d945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00fc6450-08e7-41e3-b9ea-4db81ed18a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def buildModel(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=9, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3189921c-2694-49c1-932a-ee088532649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d134c-5b92-4e55-8bf6-7feb389abcf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3\n",
    "Train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18f35f96-46f5-455d-b800-0aed02cbe601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bea4271c0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=500, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969b951-137d-4389-a3b0-ce6c05d70f43",
   "metadata": {},
   "source": [
    "### 4\n",
    "Report the test dataset accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9eb5def5-a43b-4857-a0fc-6bdd5a302553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.9000\n",
      "0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(test_X, test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988d800-4d80-4a40-97b1-9750b373941e",
   "metadata": {},
   "source": [
    "### 5 \n",
    "Try at least one other ANN design and see how the final accuracy compares to your first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25626e72-191f-4be3-9b94-0524abede2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ANN(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int(\"units\", min_value=32, max_value=512, step=8),\n",
    "                    input_dim=9,\n",
    "                    activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),))\n",
    "    \n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a976213-b90e-4a94-8256-8b85dea6b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_ANN(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e91b701-56b5-40bc-b89d-4e34ba807cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bebc68fd0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=500, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5537e30d-9883-4aad-bf99-e7a90a4abe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 32)                320       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "70cf6a7a-fb1c-4699-a9bf-189e123fcfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.9071\n",
      "0.9071428775787354\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(test_X, test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8afbf2f8-aa3e-46c4-ac8f-17c0a86d0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_ANN,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "025e5e5d-e865-4c9b-ab1b-7aaa435bd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.BayesianOptimization(\n",
    "#     hypermodel=build_ANN,\n",
    "#     objective=\"val_accuracy\",\n",
    "#     max_trials=50,\n",
    "#     executions_per_trial=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c7ffa806-fae0-4965-b8f8-16fef0cdb790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.875\n",
      "\n",
      "Best val_accuracy So Far: 0.9035714268684387\n",
      "Total elapsed time: 00h 01m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_X, train_y, epochs=2, validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "753c12d6-eb1f-45b9-bff8-ba412dfaeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyps = tuner.get_best_hyperparameters(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d70e045f-1dfd-45ad-a22f-19c9d032f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 288, 'activation': 'tanh', 'num_layers': 3, 'units_0': 384, 'dropout': False, 'units_1': 352, 'units_2': 352}\n",
      "{'units': 240, 'activation': 'tanh', 'num_layers': 3, 'units_0': 96, 'dropout': False, 'units_1': 384, 'units_2': 224}\n",
      "{'units': 240, 'activation': 'tanh', 'num_layers': 2, 'units_0': 256, 'dropout': True, 'units_1': 416, 'units_2': 224}\n",
      "{'units': 208, 'activation': 'relu', 'num_layers': 3, 'units_0': 288, 'dropout': True, 'units_1': 384, 'units_2': 416}\n",
      "{'units': 456, 'activation': 'tanh', 'num_layers': 2, 'units_0': 224, 'dropout': True, 'units_1': 480}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_hyps)):\n",
    "    \n",
    "    print(best_hyps[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba740b51-1d87-425a-8990-29548d5b3efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
