{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59e0f3c-fef5-42ef-9841-8abf1a44aad1",
   "metadata": {},
   "source": [
    "0a) Unpack the images into a folder that you can find from a Jupyter notebook. Important: do not look at the images. Part of the 'fun' of this homework is that the outlier images are hidden. This is mandatory fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22602029-70d4-4d48-814c-37161d61897f",
   "metadata": {},
   "source": [
    "0b) Write a method that converts an image into a graph. There are several steps you'll need to follow:\n",
    " * Import the image using skimage.io.imread, and normalize it to have float entries in [0,1] rather than ints [0,255];\n",
    " * Increase the contrast of the image. I did this by setting any pixel with value 0< pixel < .5 to 0, and .5 < pixel 1.0 to 1.0. I'd recommend doing the same thing, but you're welcome to try other methods.\n",
    " * Skeletonize the image. We discussed this a little in class; you should just use skimage.morphology.skeletonize. This produces an image where each line has been reduced to a single pixel width.\n",
    " * Turn the skeletonized image into a graph. Each node of this graph represents a 'live' pixel of the skeleton image, and two pixels are connected if they are adjacent. This includes the pixels that are diagonal from the current pixel. There are many ways to construct this graph; I would suggest using sklearn.neighbors.radius_neigbors_graph, with an appropriate choice of radius.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462f92a4-188c-40a0-9d1c-7e28c261dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "from skimage.morphology import skeletonize\n",
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf4a32e-17b2-4b5f-981d-4d53ca50195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_2_graph(im):\n",
    "    if len(im.shape) == 3:\n",
    "        # if im.shape[2] == 3:\n",
    "        #     im = rgb2gray(im)\n",
    "        # else:\n",
    "        #     im = rgb2gray(rgba2rgb(im)) # ignore alhpa channel\n",
    "        im = im[:,:,0]\n",
    "    \n",
    "    im = im.astype('float') / 255.0 # normalize\n",
    "    im = 1 - im\n",
    "    im[im <= 0.5] = 0.0\n",
    "    im[im >0.5] = 1.0\n",
    "    # im = skeletonize(im, method='lee')\n",
    "    im = skeletonize(im)\n",
    "    # plt.matshow(im)\n",
    "    locs_x, locs_y = np.nonzero(im)\n",
    "    adj = radius_neighbors_graph(np.stack([locs_x, locs_y]).T, math.sqrt(2))\n",
    "    \n",
    "    return nx.from_numpy_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5daa33-6795-4fa5-86fd-6bcd3f23802b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f94475264f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_2_graph(skimage.io.imread('/Users/maxperozek/CP341/Day6/Fingerprint_data/final_ims/ef2d127d.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbf1ac7-5751-4ce8-9606-82e39e31f1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f94474fc1c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_2_graph(skimage.io.imread('/Users/maxperozek/CP341/Day6/Fingerprint_data/final_ims/677fe64a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4cf7f1-354c-4688-867c-14119929a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/Users/maxperozek/CP341/Day6/Fingerprint_data/labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28bcb32-6675-493b-a929-af4325fa97b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLEAN'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[labels[0].isin(['2abaca49'])].iloc()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9d518b-0117-448c-9738-0d2377674b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 188)\n",
      "(190, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "# running into an issue with some of the files where there are some RGB/ RGBA images which don't play nice with the operations that\n",
    "print(skimage.io.imread('/Users/maxperozek/CP341/Day6/Fingerprint_data/final_ims/677fe64a.png').shape)\n",
    "print(skimage.io.imread('/Users/maxperozek/CP341/Day6/Fingerprint_data/final_ims/ef2d127d.png').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b1bc2c-d3a9-4f4f-bfd1-b2b66700311b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = '/Users/maxperozek/CP341/Day6/Fingerprint_data/final_ims/'\n",
    "graphs = 20000\n",
    "fp_graphs = []\n",
    "\n",
    "i = 0\n",
    "for file in os.listdir(rootdir):\n",
    "    if i >= graphs:\n",
    "        break\n",
    "    im = skimage.io.imread(rootdir + file)\n",
    "    # print(file)\n",
    "    gr = im_2_graph(im)\n",
    "    label = labels[labels[0].isin([file[:-4]])].iloc()[0][1]\n",
    "    fp_graphs.append((gr, label))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed9b40-7d21-4b3d-b8d5-e8f4d5e4a551",
   "metadata": {},
   "source": [
    "1a) Write a method that measures the following things about each graph:\n",
    " * A histogram of component sizes.\n",
    " * A histogram of node degrees.\n",
    " * A histogram of lengths of the components which are path graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c52dbef-c27c-4928-9982-e6ea3908e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33f090a-212e-4d92-9a35-608bbc5e4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_2_vec(gr):\n",
    "    comp_list = [len(c) for c in sorted(nx.connected_components(gr), key=len, reverse=True)]\n",
    "    comp_hist = np.histogram(comp_list, bins=[0,4,8,12,16,20,24,28,32,5000])\n",
    "    # print(comp_list)\n",
    "    # print(comp_hist)\n",
    "    # print(len(comp_list), comp_hist[0].sum())\n",
    "\n",
    "    deg_list = [gr.degree[i] for i in range(len(gr.nodes))]\n",
    "    # print(deg_list)\n",
    "    deg_hist = np.histogram(deg_list, bins=[0,1,2,3,4,5,5000])\n",
    "    # print(deg_hist)\n",
    "    \n",
    "    path_lengths = []\n",
    "    for comp in nx.connected_components(gr):\n",
    "        ind_sg = gr.subgraph(comp)\n",
    "        length = len(ind_sg.nodes)\n",
    "        # all nodes should have degree 2 except 2 nodes with degree 1\n",
    "        if (np.array([deg == 1 for node, deg in ind_sg.degree]).sum() == 2 and \n",
    "            np.array([deg == 2 for node, deg in ind_sg.degree]).sum() == length - 2):\n",
    "            path_lengths.append(len(ind_sg.nodes))\n",
    "    path_hist = np.histogram(path_lengths, bins=[0,4,8,12,16,20,24,28,32,5000])\n",
    "    # print(path_hist)\n",
    "    return np.hstack((comp_hist[0], deg_hist[0], path_hist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7fb7c6-519e-4ae5-8300-30ce4bcb20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_feat_vecs = []\n",
    "for gr, lab in fp_graphs:\n",
    "    gr_feat_vecs.append(graph_2_vec(gr))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4e08d6-8128-4090-a396-a9b8543314b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr = np.array([x[1] for x in fp_graphs])\n",
    "bin_label_arr = [0 if label == 'CLEAN' else 1 for label in label_arr]\n",
    "label_tensor = torch.tensor(bin_label_arr).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6fa447-39f4-47d2-859e-534e08dc6cc1",
   "metadata": {},
   "source": [
    "1b) Train a simple neural network model to predict whether a fingerprint is damaged or not from the features you collected earlier. Try some of the best practices we talked about today for training neural networks. You should set aside a random chunk of your data as a 'test' set, and report the final accuracy on that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b808f7d8-8177-4a81-8e69-72c8acd08a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(gr_feat_vecs)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e36cbd-f741-447a-9b78-30d9bbd81339",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.random.choice(np.arange(len(gr_feat_vecs)), size=int(len(gr_feat_vecs)/10), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b00e06-b098-416a-a7c4-bf674d634558",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.take(np.array(gr_feat_vecs), test_idx, 0)\n",
    "test_labels = np.take(np.array(label_tensor), test_idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33aa3f7-87a4-4147-8226-0b4e84663e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.take(np.array(gr_feat_vecs), [i for i in range(len(gr_feat_vecs)) if not i in test_idx], 0)\n",
    "train_labels = np.take(np.array(label_tensor), [i for i in range(len(gr_feat_vecs)) if not i in test_idx], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4ccc7a9-a229-432d-bb82-738720f32868",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(train).float()\n",
    "train_labels = torch.tensor(train_labels).float()\n",
    "\n",
    "test = torch.tensor(test).float()\n",
    "test_labels = torch.tensor(test_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac7e7fe-faf1-4923-a692-f71ee2f88476",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net_classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(24,8),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(8,8),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(8,16),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(16,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a93e8e-4609-4b59-8586-40f97c7ab375",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d0a5ad-9b78-4c03-a1b0-5099b9a90362",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neural_net_classifier.parameters(), .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba736274-012f-4c06-8807-b48166d6989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/mpc19fxd7zz_dr0tr65kskdh0000gn/T/ipykernel_86878/122459794.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_tensor = torch.tensor(train).float()\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor(train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e898470-d78c-4957-a546-c5be9734b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = torch.sigmoid(neural_net_classifier(train))\n",
    "    error = error_function(predictions, train_labels)\n",
    "    # print(error)\n",
    "    error.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99b788bf-5757-4d96-8b53-4a2b40ff757e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2242, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715442a2-c097-455b-b0e8-93d4ca07bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = torch.sigmoid(neural_net_classifier(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "103ea29c-9154-45c8-a07a-acfc7b13e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "error = error_function(test_predictions, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1c65aaa-6989-4ef7-a5ca-e16e88a1c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2051, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685ef0-eb71-4f11-ad14-4cee706d92d6",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2d5c0-0496-431f-9002-656299670f58",
   "metadata": {},
   "source": [
    "Fingerprint analysis falls into the field of biometric identification --a field whose ethics are widely debated. While the field of biometric identification is broad and developing quickly with DNA and facial recognition technology, fingerprint analysis was the original means of modern biometric identification and it has become a fixture of crime and detective media in the last century. In the last 2 decades, fingerprints have been used widely outside of law enforcement in applications such as: personal and private security, border control, and health organizations. Additionally, advances in the ability to analyze fingerprints by powerful governments like the Next Generation Identification system (NGI) which is operated by the FBI have significantly increased the number of 'matches' found in searches relating to crimes. In his paper titled: \"Biometric Identification, Law and Ethics: The Rise of Biometric Identification: Fingerprints and Applied Ethics\" Marcus Smith notes that the scale and heirarchical structure of the organizations which implement large scale biometric analysis can result in a diminished sense of moral responsibility since their role is merely to carry out the instructions of their supperiors. The distributed moral responsibility from these large organizations for biometric analysis makes the responsibility for the ethical implications of fingerprint analysis more ambiguous. One key ethical concern is the idea that fingerprints (as with other biometric identification data) are the property of an individual, and the means by which authorities collect this data may be coercive and may impede on the right of an individual to not self incriminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e42ef6-ba19-4adb-acc5-1a9c5f7cfbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
